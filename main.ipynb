{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Specific Language for Decoding\n",
    "\n",
    "frontier research labs that provide closed source inference via their api are too greedy to share their logits with us and are not up to date with the best decoding practices.\n",
    "\n",
    "we basically only get the temperature parameter to play around and that's usually it. maybe also top_k if we are lucky.\n",
    "\n",
    "granted, even if we had the logits, having to do the decoding on our machine would be a throughput-nightmare (thanks to @stochasm for pointing this out). so what should we do?\n",
    "\n",
    "the answer was provided by @lun_aaaaa as an off-hand remark (I assume), but it's actually brilliant.\n",
    "\n",
    "I have decided to take that idea and propose to my knowledge the first domain specific language to define sampling behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as of now, it only consists of 3 commands:\n",
    "\n",
    "- `sort`, which sorts the logit tensor (default is descending order, `sort +` for ascending order)\n",
    "\n",
    "- `slice n:m`, which slices the logit tensor from the $n$-th to $m$-th index. this is implemented as masking the logits at the positions that are out of bounds\n",
    "\n",
    "- `threshold op n`, which masks all the logits that are above or belov the threshold (depending on `op`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can create `top_k` sampling throught this dsl code:\n",
    "\n",
    "```\n",
    "sort\n",
    "slice k:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "likewise, we can recover `min_p` through the following code:\n",
    "\n",
    "```\n",
    "sort\n",
    "theshold >p\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
